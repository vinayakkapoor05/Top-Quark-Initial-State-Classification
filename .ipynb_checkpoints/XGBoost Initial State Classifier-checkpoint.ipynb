{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90e6b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import math\n",
    "import uproot\n",
    "import xgboost as xgb\n",
    "plt.rcParams.update({'font.family': 'serif', 'font.serif': ['Times New Roman']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808dfd9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "file not found\n\n    '/Users/vinayakkapoor/Downloads/ee_modified_root_1_allorentz_gen.root'\n\nFiles may be specified as:\n   * str/bytes: relative or absolute filesystem path or URL, without any colons\n         other than Windows drive letter or URL schema.\n         Examples: \"rel/file.root\", \"C:\\abs\\file.root\", \"http://where/what.root\"\n   * str/bytes: same with an object-within-ROOT path, separated by a colon.\n         Example: \"rel/file.root:tdirectory/ttree\"\n   * pathlib.Path: always interpreted as a filesystem path or URL only (no\n         object-within-ROOT path), regardless of whether there are any colons.\n         Examples: Path(\"rel:/file.root\"), Path(\"/abs/path:stuff.root\")\n\nFunctions that accept many files (uproot.iterate, etc.) also allow:\n   * glob syntax in str/bytes and pathlib.Path.\n         Examples: Path(\"rel/*.root\"), \"/abs/*.root:tdirectory/ttree\"\n   * dict: keys are filesystem paths, values are objects-within-ROOT paths.\n         Example: {\"/data_v1/*.root\": \"ttree_v1\", \"/data_v2/*.root\": \"ttree_v2\"}\n   * already-open TTree objects.\n   * iterables of the above.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/uproot/source/file.py:112\u001b[0m, in \u001b[0;36mMemmapSource._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/memmap.py:228\u001b[0m, in \u001b[0;36mmemmap.__new__\u001b[0;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 228\u001b[0m     f_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m f_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/vinayakkapoor/Downloads/ee_modified_root_1_allorentz_gen.root'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/uproot/source/file.py:36\u001b[0m, in \u001b[0;36mFileResource.__init__\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39m_FileNotFoundError:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/vinayakkapoor/Downloads/ee_modified_root_1_allorentz_gen.root'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43muproot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/vinayakkapoor/Downloads/ee_modified_root_1_allorentz_gen.root\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/uproot/reading.py:141\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, object_cache, array_cache, custom_classes, decompression_executor, interpretation_executor, **options)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39misstr(file_path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m ):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a string, pathlib.Path, an object with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m methods, or a length-1 dict of \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mfile_path: object_path}}, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mrepr\u001b[39m(path))\n\u001b[1;32m    139\u001b[0m     )\n\u001b[0;32m--> 141\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mReadOnlyFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43marray_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marray_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompression_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpretation_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# NOTE: a comma after **options breaks Python 2\u001b[39;49;00m\n\u001b[1;32m    149\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m object_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mroot_directory\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/uproot/reading.py:580\u001b[0m, in \u001b[0;36mReadOnlyFile.__init__\u001b[0;34m(self, file_path, object_cache, array_cache, custom_classes, decompression_executor, interpretation_executor, **options)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_before_create_source()\n\u001b[1;32m    577\u001b[0m Source, file_path \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39mfile_path_to_source_class(\n\u001b[1;32m    578\u001b[0m     file_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_source \u001b[38;5;241m=\u001b[39m \u001b[43mSource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# NOTE: a comma after **options breaks Python 2\u001b[39;49;00m\n\u001b[1;32m    582\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_before_get_chunks()\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin_chunk_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m _file_header_fields_big\u001b[38;5;241m.\u001b[39msize:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/uproot/source/file.py:108\u001b[0m, in \u001b[0;36mMemmapSource.__init__\u001b[0;34m(self, file_path, **options)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_requested_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path \u001b[38;5;241m=\u001b[39m file_path\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/uproot/source/file.py:118\u001b[0m, in \u001b[0;36mMemmapSource._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m opts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fallback_opts)\n\u001b[1;32m    117\u001b[0m opts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_fallback_workers\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fallback \u001b[38;5;241m=\u001b[39m \u001b[43muproot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultithreadedFileSource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# NOTE: a comma after **opts breaks Python 2\u001b[39;49;00m\n\u001b[1;32m    120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/uproot/source/file.py:250\u001b[0m, in \u001b[0;36mMultithreadedFileSource.__init__\u001b[0;34m(self, file_path, **options)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_requested_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path \u001b[38;5;241m=\u001b[39m file_path\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/uproot/source/file.py:254\u001b[0m, in \u001b[0;36mMultithreadedFileSource._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mResourceThreadPoolExecutor(\n\u001b[0;32m--> 254\u001b[0m         [FileResource(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers)]\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/uproot/source/file.py:254\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mResourceThreadPoolExecutor(\n\u001b[0;32m--> 254\u001b[0m         [\u001b[43mFileResource\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers)]\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/uproot/source/file.py:38\u001b[0m, in \u001b[0;36mFileResource.__init__\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39m_FileNotFoundError:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39m_file_not_found(file_path)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: file not found\n\n    '/Users/vinayakkapoor/Downloads/ee_modified_root_1_allorentz_gen.root'\n\nFiles may be specified as:\n   * str/bytes: relative or absolute filesystem path or URL, without any colons\n         other than Windows drive letter or URL schema.\n         Examples: \"rel/file.root\", \"C:\\abs\\file.root\", \"http://where/what.root\"\n   * str/bytes: same with an object-within-ROOT path, separated by a colon.\n         Example: \"rel/file.root:tdirectory/ttree\"\n   * pathlib.Path: always interpreted as a filesystem path or URL only (no\n         object-within-ROOT path), regardless of whether there are any colons.\n         Examples: Path(\"rel:/file.root\"), Path(\"/abs/path:stuff.root\")\n\nFunctions that accept many files (uproot.iterate, etc.) also allow:\n   * glob syntax in str/bytes and pathlib.Path.\n         Examples: Path(\"rel/*.root\"), \"/abs/*.root:tdirectory/ttree\"\n   * dict: keys are filesystem paths, values are objects-within-ROOT paths.\n         Example: {\"/data_v1/*.root\": \"ttree_v1\", \"/data_v2/*.root\": \"ttree_v2\"}\n   * already-open TTree objects.\n   * iterables of the above.\n"
     ]
    }
   ],
   "source": [
    "data = uproot.open(\"/Users/vinayakkapoor/Downloads/ee_modified_root_1_allorentz_gen.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = data['ttBar_treeVariables_step8;21;1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d3b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_mask = tree['production_mode'].array(library='numpy') == 1\n",
    "zeros_mask = tree['production_mode'].array(library='numpy') == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ones = torch.cat([torch.from_numpy(tree[key].array(library='numpy')[ones_mask][:, None]).float() for key in tree.keys() if (key != 'production_mode' and key != 'eventWeight' and key != '__index__')], dim=1) \n",
    "\n",
    "X_zeros = torch.cat([torch.from_numpy(tree[key].array(library='numpy')[zeros_mask][:, None]).float() for key in tree.keys() if (key != 'production_mode' and key != 'eventWeight' and key != '__index__')], dim=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc64050",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.7 # 70% of the data is training\n",
    "valid_split = 0.2 # 20% of the data is validation\n",
    "test_split = 0.1 # 10% of the data is testing\n",
    "\n",
    "num_ones = len(X_ones) # calculate total number of data points with class labels = 1\n",
    "num_zeros = len(X_zeros) # calculate total number of data points with class labels = 0\n",
    "\n",
    "# split the data into training data\n",
    "training_data = torch.cat((X_ones[:math.ceil(num_ones * train_split)], X_zeros[:math.ceil(num_zeros * train_split)]))\n",
    "# split the labels for just training data\n",
    "training_labels = torch.cat((torch.ones(math.ceil(num_ones * train_split)), torch.zeros(math.ceil(num_zeros * train_split))))\n",
    "\n",
    "# split the data into validation data\n",
    "validation_data = torch.cat((X_ones[math.ceil(num_ones * train_split):math.ceil(num_ones * (train_split + valid_split))],\n",
    "                             X_zeros[math.ceil(num_zeros * train_split):math.ceil(num_zeros * (train_split + valid_split))]))\n",
    "validation_labels = torch.cat((torch.ones(math.ceil(num_ones * valid_split)), torch.zeros(math.ceil(num_zeros * valid_split))))\n",
    "\n",
    "# split the data into testing data\n",
    "test_data = torch.cat((X_ones[math.ceil(num_ones * (train_split + valid_split)):],\n",
    "                      X_zeros[math.ceil(num_zeros * (train_split + valid_split)):]))\n",
    "test_labels = torch.cat((torch.ones(len(X_ones[math.ceil(num_ones * (train_split + valid_split)):])),\n",
    "                        torch.zeros(len(X_zeros[math.ceil(num_zeros * (train_split + valid_split)):]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf30267",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ones_in_training = int(train_split * num_ones)\n",
    "num_zeros_in_training = int(train_split * num_zeros)\n",
    "\n",
    "# upsample the training data\n",
    "if num_ones_in_training > num_zeros_in_training: # need to upsample the zeros\n",
    "    multiplicity = math.ceil(num_ones_in_training / num_zeros_in_training)\n",
    "    \n",
    "    training_data = torch.cat((training_data[training_labels == 1], training_data[training_labels == 0].repeat(multiplicity, 1)[:num_ones_in_training]))\n",
    "    training_labels = torch.cat((training_labels[training_labels == 1][:num_zeros_in_training], training_labels[training_labels == 0].repeat(multiplicity)[:num_ones_in_training]))\n",
    "elif num_zeros_in_training > num_ones_in_training: # need to upsample the ones\n",
    "    multiplicity = math.ceil(num_zeros_in_training / num_ones_in_training)\n",
    "    \n",
    "    training_data = torch.cat((training_data[training_labels == 1].repeat(multiplicity, 1)[:num_zeros_in_training], training_data[training_labels == 0]))\n",
    "    training_labels = torch.cat((training_labels[training_labels == 1].repeat(multiplicity)[:num_zeros_in_training], training_labels[training_labels == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ones_in_validation = len(validation_labels[validation_labels == 1])\n",
    "num_zeros_in_validation = len(validation_labels[validation_labels == 0])\n",
    "\n",
    "# upsample the validation data\n",
    "if num_ones_in_validation > num_zeros_in_validation: # need to upsample the zeros\n",
    "    multiplicity = math.ceil(num_ones_in_validation / num_zeros_in_validation)\n",
    "    \n",
    "    validation_data = torch.cat((validation_data[validation_labels == 1], validation_data[validation_labels == 0].repeat(multiplicity, 1)[:num_ones_in_validation]))\n",
    "    validation_labels = torch.cat((validation_labels[validation_labels == 1][:num_zeros_in_validation], validation_labels[validation_labels == 0].repeat(multiplicity)[:num_ones_in_validation]))\n",
    "elif num_zeros_in_validation > num_ones_in_validation: # need to upsample the ones\n",
    "    multiplicity = math.ceil(num_zeros_in_validation / num_ones_in_validation)\n",
    "    \n",
    "    validation_data = torch.cat((validation_data[validation_labels == 1].repeat(multiplicity, 1)[:num_zeros_in_validation], validation_data[validation_labels == 0]))\n",
    "    validation_labels = torch.cat((validation_labels[validation_labels == 1].repeat(multiplicity)[:num_zeros_in_validation], validation_labels[validation_labels == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the data\n",
    "standardized_training_data = (training_data - torch.mean(training_data, 0)) / torch.std(training_data, 0, True)\n",
    "standardized_validation_data = (validation_data - torch.mean(validation_data, 0)) / torch.std(validation_data, 0, True)\n",
    "standardized_testing_data = (test_data - torch.mean(test_data, 0)) / torch.std(test_data, 0, True)\n",
    "\n",
    "# replace nans with 0 for zero width values\n",
    "standardized_training_data = torch.nan_to_num(standardized_training_data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "standardized_validation_data = torch.nan_to_num(standardized_validation_data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "standardized_testing_data = torch.nan_to_num(standardized_testing_data, nan=0.0, posinf=0.0, neginf=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f67a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=0,max_depth=5,reg_alpha = 10, n_estimators = 300,learning_rate = 0.01)\n",
    "xgb_model.fit(standardized_training_data, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_proba = xgb_model.predict_proba(standardized_testing_data)[:,1]\n",
    "\n",
    "# Calculate the AUC\n",
    "auc = roc_auc_score(test_labels, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, y_pred_proba,)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, 'black')\n",
    "ax.grid(linestyle='--', linewidth='0.5', color='gray', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "\n",
    "ax.set_title('ROC Curve', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f90ccddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:45] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.05,0.01],\n",
    "    #learning rate increase exponentially \n",
    "    'n_estimators': [100, 200,300],\n",
    "    #'subsample': [0.8, 1],\n",
    "    #'colsample_bytree': [0.8, 1],\n",
    "    'reg_alpha': [0.1, 1, 10],\n",
    "}\n",
    "#lasso\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "xgb_model.fit(standardized_training_data, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6f005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_64sp5n4yln/croot/pytorch_1669252639708/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return array[key] if axis == 0 else array[:, key]\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_64sp5n4yln/croot/pytorch_1669252639708/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return array[key] if axis == 0 else array[:, key]\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_64sp5n4yln/croot/pytorch_1669252639708/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return array[key] if axis == 0 else array[:, key]\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_64sp5n4yln/croot/pytorch_1669252639708/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return array[key] if axis == 0 else array[:, key]\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_64sp5n4yln/croot/pytorch_1669252639708/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return array[key] if axis == 0 else array[:, key]\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_64sp5n4yln/croot/pytorch_1669252639708/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return array[key] if axis == 0 else array[:, key]\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_64sp5n4yln/croot/pytorch_1669252639708/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return array[key] if axis == 0 else array[:, key]\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:202: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_64sp5n4yln/croot/pytorch_1669252639708/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return array[key] if axis == 0 else array[:, key]\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/vinayakkapoor/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(standardized_training_data, training_labels)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best AUC-ROC score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5e0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save intermediate results \n",
    "#save model, predictions\n",
    "#save training loss\n",
    "#repeat gridsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8a28c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
